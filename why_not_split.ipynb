{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903bfea2-68bf-45d2-8c45-a626f62ad02e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca169f6f-62ed-48ce-8818-8fae8b26c229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61083cb8-8bb1-4cf7-b30c-8f858ff823ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport rnn, lstm\n",
    "from lstm import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c5a4370-0238-498d-b616-4e34dc9236d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LSTM(128, 128, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49a3d31-fcd4-431b-bf68-386eb7ee780f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (layers): ModuleList(\n",
       "    (0-4): 5 x LSTMBase(\n",
       "      (sigmoid): Sigmoid()\n",
       "      (tanh): Tanh()\n",
       "      (fc_ii): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_hi): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_if): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_hf): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_ig): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_hg): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_io): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (fc_ho): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d7ff1b-af13-41f8-9f63-53055aeea2e9",
   "metadata": {},
   "source": [
    "Here we test the inference time cost of two ways of implementing LSTM: one is to create a nn.Linear submodule for every transformation; the other is to create big chunks of weights first and split them into smaller chunks. Many chose to implement via the second way but it's actually much slower.  \n",
    "In this experiment, the model would create both nn.Linear submodules and big chunks of weights and split them into smaller weights, whether split is enabled or not. So the difference of inference time is purely related to the computational efficiency of these two ways since the number of parameters are the same.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb37e052-d53e-462e-ac4e-a4617a543ab6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.103795528411865\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(10):\n",
    "    output, state = model(torch.randn([1000, 100, 128]))\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b2928e-8a2c-421a-a207-e7859d4c871a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.983369588851929\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for _ in range(10):\n",
    "    output, state = model(torch.randn([1000, 100, 128]), split=False)\n",
    "t1 = time.time()\n",
    "print(t1-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756aff24-2363-4799-b4dc-4326126ad457",
   "metadata": {},
   "source": [
    "We show that whether using split or not, the number of parameters are the same both way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "310789a2-3d27-42e5-a0a8-2feef0f51229",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linear_param_nums = 0\n",
    "parameter_param_nums = 0\n",
    "for pn, p in model.named_parameters():\n",
    "    if pn.split('.')[2].startswith('fc'):\n",
    "        linear_param_nums += p.numel()\n",
    "    else:\n",
    "        parameter_param_nums += p.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ff163cf-a869-4f44-9c8b-8dd845e487e4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660480"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_param_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d004b690-e068-4933-b012-45c4c8db2ac4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660480"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_param_nums"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
